#!/usr/bin/env python3
"""ä½¿ç”¨ DeepCFR è®­ç»ƒå¾·å·æ‰‘å…‹ç­–ç•¥

æ”¯æŒå¤š GPU å¹¶è¡Œè®­ç»ƒï¼ˆDataParallelï¼‰
"""

import os
# ç¦ç”¨ torch.compile ä»¥é¿å…å¯¼å…¥é—®é¢˜
os.environ.setdefault('TORCH_COMPILE_DISABLE', '1')

import argparse
import sys
import time
import json
import numpy as np
import torch
import torch.nn as nn

import pyspiel
from open_spiel.python.games import pokerkit_wrapper  # noqa: F401
from open_spiel.python.pytorch import deep_cfr
from open_spiel.python import policy
from deep_cfr_with_feature_transform import DeepCFRWithFeatureTransform
from deep_cfr_simple_feature import DeepCFRSimpleFeature


def get_available_gpus():
    """è·å–å¯ç”¨çš„ GPU åˆ—è¡¨"""
    if not torch.cuda.is_available():
        return []
    return list(range(torch.cuda.device_count()))


def print_gpu_info():
    """æ‰“å°æ‰€æœ‰å¯ç”¨ GPU çš„ä¿¡æ¯"""
    if not torch.cuda.is_available():
        print("  æ²¡æœ‰å¯ç”¨çš„ GPU")
        return
    
    num_gpus = torch.cuda.device_count()
    print(f"  å¯ç”¨ GPU æ•°é‡: {num_gpus}")
    for i in range(num_gpus):
        props = torch.cuda.get_device_properties(i)
        print(f"    GPU {i}: {props.name}")
        print(f"      - å†…å­˜: {props.total_memory / 1e9:.2f} GB")
        print(f"      - è®¡ç®—èƒ½åŠ›: {props.major}.{props.minor}")


def json_serialize(obj):
    """å°†å¯¹è±¡è½¬æ¢ä¸º JSON å¯åºåˆ—åŒ–çš„æ ¼å¼"""
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, (np.integer, np.floating)):
        return float(obj)
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, dict):
        return {k: json_serialize(v) for k, v in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [json_serialize(item) for item in obj]
    else:
        return obj


def create_save_directory(save_prefix, save_dir="models"):
    """åˆ›å»ºä¿å­˜ç›®å½•ï¼Œå¦‚æœå·²å­˜åœ¨åˆ™æ·»åŠ æ—¶é—´æˆ³
    
    Args:
        save_prefix: ä¿å­˜æ–‡ä»¶å‰ç¼€
        save_dir: åŸºç¡€ä¿å­˜ç›®å½•ï¼ˆé»˜è®¤ "models"ï¼‰
    
    Returns:
        str: åˆ›å»ºçš„ç›®å½•è·¯å¾„
    """
    # åˆ›å»ºåŸºç¡€ç›®å½•
    base_dir = save_dir
    if not os.path.exists(base_dir):
        os.makedirs(base_dir)
    
    # åˆ›å»ºæ¨¡å‹å­ç›®å½•
    model_dir = os.path.join(base_dir, save_prefix)
    
    # å¦‚æœç›®å½•å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³
    if os.path.exists(model_dir):
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        model_dir = f"{model_dir}_{timestamp}"
    
    # åˆ›å»ºç›®å½•
    os.makedirs(model_dir, exist_ok=True)
    
    return model_dir

def save_checkpoint(deep_cfr_solver, game, model_dir, save_prefix, iteration, is_final=False):
    """ä¿å­˜è®­ç»ƒ checkpoint
    
    Args:
        deep_cfr_solver: DeepCFR æ±‚è§£å™¨
        game: æ¸¸æˆå®ä¾‹
        model_dir: æ¨¡å‹ä¿å­˜ç›®å½•
        save_prefix: ä¿å­˜æ–‡ä»¶å‰ç¼€
        iteration: å½“å‰è¿­ä»£æ¬¡æ•°
        is_final: æ˜¯å¦æ˜¯æœ€ç»ˆæ¨¡å‹
    """
    if is_final:
        suffix = ""
        checkpoint_dir = model_dir
    else:
        suffix = f"_iter{iteration}"
        checkpoint_dir = os.path.join(model_dir, "checkpoints")
        os.makedirs(checkpoint_dir, exist_ok=True)
    
    # ä¿å­˜ç­–ç•¥ç½‘ç»œ
    policy_path = os.path.join(checkpoint_dir, f"{save_prefix}_policy_network{suffix}.pt")
    policy_net = deep_cfr_solver._policy_network
    if isinstance(policy_net, nn.DataParallel):
        torch.save(policy_net.module.state_dict(), policy_path)
    else:
        torch.save(policy_net.state_dict(), policy_path)
    
    # ä¿å­˜ä¼˜åŠ¿ç½‘ç»œ
    for player in range(game.num_players()):
        advantage_path = os.path.join(checkpoint_dir, f"{save_prefix}_advantage_player_{player}{suffix}.pt")
        adv_net = deep_cfr_solver._advantage_networks[player]
        if isinstance(adv_net, nn.DataParallel):
            torch.save(adv_net.module.state_dict(), advantage_path)
        else:
            torch.save(adv_net.state_dict(), advantage_path)
    
    return checkpoint_dir


def train_deep_cfr(
    num_players=2,
    num_iterations=10,
    num_traversals=20,
    policy_layers=(64, 64),
    advantage_layers=(32, 32),
    learning_rate=1e-3,
    memory_capacity=int(1e6),
    save_prefix="deepcfr_texas",
    use_gpu=True,
    skip_nashconv=False,
    eval_interval=10,
    eval_with_games=False,
    save_history=True,
    save_dir="models",
    use_feature_transform=True,  # æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨ç‰¹å¾è½¬æ¢å±‚
    use_simple_feature=True,  # æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨ç®€å•ç‰ˆæœ¬ï¼ˆç›´æ¥æ‹¼æ¥7ç»´ç‰¹å¾ï¼Œæ¨èTrueï¼‰
    transformed_size=150,  # æ–°å¢ï¼šè½¬æ¢åçš„ç‰¹å¾å¤§å°ï¼ˆä»…ç”¨äºå¤æ‚ç‰ˆæœ¬ï¼‰
    use_hybrid_transform=True,  # æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨æ··åˆç‰¹å¾è½¬æ¢ï¼ˆä»…ç”¨äºå¤æ‚ç‰ˆæœ¬ï¼‰
    betting_abstraction="fcpa", # æ–°å¢ï¼šä¸‹æ³¨æŠ½è±¡æ¨¡å¼
    multi_gpu=False,  # æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨å¤š GPU å¹¶è¡Œ
    gpu_ids=None,  # æ–°å¢ï¼šæŒ‡å®šä½¿ç”¨çš„ GPU ID åˆ—è¡¨ï¼ˆNone è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰å¯ç”¨ GPUï¼‰
    checkpoint_interval=0,  # æ–°å¢ï¼šcheckpoint ä¿å­˜é—´éš”ï¼ˆ0 è¡¨ç¤ºä¸ä¿å­˜ä¸­é—´ checkpointï¼‰
):
    """ä½¿ç”¨ DeepCFR è®­ç»ƒå¾·å·æ‰‘å…‹ç­–ç•¥
    
    Args:
        num_players: ç©å®¶æ•°é‡
        num_iterations: è¿­ä»£æ¬¡æ•°
        num_traversals: æ¯æ¬¡è¿­ä»£çš„éå†æ¬¡æ•°
        policy_layers: ç­–ç•¥ç½‘ç»œå±‚å¤§å°
        advantage_layers: ä¼˜åŠ¿ç½‘ç»œå±‚å¤§å°
        learning_rate: å­¦ä¹ ç‡
        memory_capacity: å†…å­˜å®¹é‡
        save_prefix: ä¿å­˜æ–‡ä»¶å‰ç¼€
        betting_abstraction: ä¸‹æ³¨æŠ½è±¡ (fcpa, fchpa, etc.)
        multi_gpu: æ˜¯å¦ä½¿ç”¨å¤š GPU å¹¶è¡Œè®­ç»ƒ
        gpu_ids: æŒ‡å®šä½¿ç”¨çš„ GPU ID åˆ—è¡¨ï¼ˆNone è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰å¯ç”¨ GPUï¼‰
        checkpoint_interval: checkpoint ä¿å­˜é—´éš”ï¼ˆ0 è¡¨ç¤ºä¸ä¿å­˜ï¼Œå»ºè®®è®¾ä¸º 100-500ï¼‰
    """
    print("=" * 70)
    print("DeepCFR è®­ç»ƒ - å¾·å·æ‰‘å…‹")
    print("=" * 70)
    
    # æ£€æŸ¥ PyTorch å’Œ GPU
    print(f"\nPyTorch ç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
    print_gpu_info()
    
    # è®¾ç½®è®¾å¤‡å’Œå¤š GPU
    available_gpus = get_available_gpus()
    use_multi_gpu = False
    
    if use_gpu and torch.cuda.is_available():
        if multi_gpu and len(available_gpus) > 1:
            # å¤š GPU æ¨¡å¼
            if gpu_ids is None:
                gpu_ids = available_gpus
            else:
                # éªŒè¯æŒ‡å®šçš„ GPU ID æ˜¯å¦æœ‰æ•ˆ
                gpu_ids = [gid for gid in gpu_ids if gid in available_gpus]
            
            if len(gpu_ids) > 1:
                use_multi_gpu = True
                device = torch.device(f"cuda:{gpu_ids[0]}")  # ä¸» GPU
                print(f"\nğŸš€ å¤š GPU æ¨¡å¼å·²å¯ç”¨")
                print(f"  ä½¿ç”¨çš„ GPU: {gpu_ids}")
                print(f"  ä¸»è®¾å¤‡: {device}")
            else:
                device = torch.device("cuda:0")
                print(f"\nâš ï¸ åªæœ‰ä¸€ä¸ªæœ‰æ•ˆ GPUï¼Œä½¿ç”¨å• GPU æ¨¡å¼")
        else:
            device = torch.device("cuda:0")
            if multi_gpu:
                print(f"\nâš ï¸ åªæ£€æµ‹åˆ°ä¸€ä¸ª GPUï¼Œä½¿ç”¨å• GPU æ¨¡å¼")
    else:
        device = torch.device("cpu")
    
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¸¸æˆ - ä½¿ç”¨ universal_poker å› ä¸º DeepCFR éœ€è¦ information_state_tensor
    # pokerkit_wrapper ä¸æ”¯æŒ tensorï¼Œæ‰€ä»¥ä¸èƒ½ç”¨äº DeepCFR
    print(f"\n[1/4] åˆ›å»ºæ¸¸æˆ ({num_players}äººæ— é™æ³¨å¾·å·)...")
    print("  æ³¨æ„: ä½¿ç”¨ universal_poker (DeepCFR éœ€è¦ information_state_tensor)")
    print(f"  ä¸‹æ³¨æŠ½è±¡: {betting_abstraction}")
    sys.stdout.flush()
    
    # é…ç½® blinds å’Œ firstPlayer
    if num_players == 2:
        # 2äººåœº (Heads-Up): 
        # P1 æ˜¯ Button/SB (è¡ŒåŠ¨: Preflopå…ˆ, Postflopå)
        # P0 æ˜¯ BB (è¡ŒåŠ¨: Preflopå, Postflopå…ˆ)
        # Blinds: P0=100(BB), P1=50(SB)
        blinds_str = "100 50" 
        first_player_str = "2 1 1 1"  # Preflop: P1(SB), Postflop: P0(BB)
    else:
        # å¤šäººåœº (e.g. 6-max):
        # P0 æ˜¯ SB
        # P1 æ˜¯ BB
        # P2 æ˜¯ UTG
        # ...
        # P(N-1) æ˜¯ Button
        # Blinds: P0=50(SB), P1=100(BB), Others=0
        blinds_list = ["50", "100"] + ["0"] * (num_players - 2)
        blinds_str = " ".join(blinds_list)
        # Preflop: UTG (P2, index 3) acts first
        # Postflop: SB (P0, index 1) acts first
        # æ³¨æ„: universal_poker ä½¿ç”¨ 1-indexedï¼Œæ‰€ä»¥ player 2 = 3, player 0 = 1
        first_player_str = " ".join(["3"] + ["1"] * 3)
    
    # stacks_str ä¿æŒä¸€è‡´
    stacks_str = " ".join(["2000"] * num_players)
    
    game_string = (
        f"universal_poker("
        f"betting=nolimit,"
        f"numPlayers={num_players},"
        f"numRounds=4,"
        f"blind={blinds_str},"
        f"stack={stacks_str},"
        f"numHoleCards=2,"
        f"numBoardCards=0 3 1 1,"
        f"firstPlayer={first_player_str},"
        f"numSuits=4,"
        f"numRanks=13,"
        f"bettingAbstraction={betting_abstraction}"  # æ·»åŠ å‚æ•°
        f")"
    )
    
    print(f"  æ­£åœ¨åŠ è½½æ¸¸æˆ...")
    print(f"  æ¸¸æˆå­—ç¬¦ä¸²: {game_string}")
    sys.stdout.flush()
    
    try:
        game = pyspiel.load_game(game_string)
        print(f"  âœ“ æ¸¸æˆåˆ›å»ºæˆåŠŸ: {game.get_type().short_name}")
        print(f"  âœ“ åŠ¨ä½œæ•°é‡: {game.num_distinct_actions()}")
        sys.stdout.flush()
        
        # éªŒè¯ tensor æ”¯æŒ
        print(f"  éªŒè¯ tensor æ”¯æŒ...")
        sys.stdout.flush()
        state = game.new_initial_state()
        tensor = state.information_state_tensor(0)
        print(f"  âœ“ ä¿¡æ¯çŠ¶æ€å¼ é‡å¤§å°: {len(tensor)}")
        sys.stdout.flush()
    except Exception as e:
        print(f"  âœ— æ¸¸æˆåˆ›å»ºå¤±è´¥: {e}")
        print(f"  å°è¯•çš„æ¸¸æˆå­—ç¬¦ä¸²: {game_string}")
        import traceback
        traceback.print_exc()
        raise
    
    # åˆ›å»ºæ±‚è§£å™¨
    print(f"\n[2/4] åˆ›å»º DeepCFR æ±‚è§£å™¨...")
    print(f"  ç­–ç•¥ç½‘ç»œ: {policy_layers}")
    print(f"  ä¼˜åŠ¿ç½‘ç»œ: {advantage_layers}")
    print(f"  è¿­ä»£æ¬¡æ•°: {num_iterations}")
    print(f"  æ¯æ¬¡è¿­ä»£éå†æ¬¡æ•°: {num_traversals}")
    sys.stdout.flush()
    
    print(f"  æ­£åœ¨åˆ›å»ºæ±‚è§£å™¨ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿï¼‰...")
    sys.stdout.flush()
    
    try:
        if use_feature_transform:
            if use_simple_feature:
                # ä½¿ç”¨ç®€å•ç‰ˆæœ¬ï¼šç›´æ¥æ‹¼æ¥7ç»´æ‰‹åŠ¨ç‰¹å¾
                deep_cfr_solver = DeepCFRSimpleFeature(
                    game,
                    policy_network_layers=policy_layers,
                    advantage_network_layers=advantage_layers,
                    num_iterations=num_iterations,
                    num_traversals=num_traversals,
                    learning_rate=learning_rate,
                    batch_size_advantage=None,
                    batch_size_strategy=None,
                    memory_capacity=memory_capacity,
                    device=device,
                    multi_gpu=use_multi_gpu,
                    gpu_ids=gpu_ids if use_multi_gpu else None,
                )
                print("  âœ“ DeepCFR Simple Feature æ±‚è§£å™¨åˆ›å»ºæˆåŠŸï¼ˆç®€å•ç‰ˆæœ¬ï¼‰")
                print(f"  âœ“ åŸå§‹ä¿¡æ¯çŠ¶æ€å¤§å°: {deep_cfr_solver._embedding_size}")
                print(f"  âœ“ æ‰‹åŠ¨ç‰¹å¾ç»´åº¦: 7 (ç›´æ¥æ‹¼æ¥)")
                print(f"  âœ“ MLPè¾“å…¥ç»´åº¦: {deep_cfr_solver._embedding_size + 7}")
                print(f"  âœ“ è¯´æ˜: ä¿¡æ¯çŠ¶æ€({deep_cfr_solver._embedding_size}ç»´) + æ‰‹åŠ¨ç‰¹å¾(7ç»´) -> MLP")
            else:
                # ä½¿ç”¨å¤æ‚ç‰ˆæœ¬ï¼šç‰¹å¾è½¬æ¢å±‚
                deep_cfr_solver = DeepCFRWithFeatureTransform(
                    game,
                    policy_network_layers=policy_layers,
                    advantage_network_layers=advantage_layers,
                    transformed_size=transformed_size,
                    use_hybrid_transform=use_hybrid_transform,
                    num_iterations=num_iterations,
                    num_traversals=num_traversals,
                    learning_rate=learning_rate,
                    batch_size_advantage=None,
                    batch_size_strategy=None,
                    memory_capacity=memory_capacity,
                    device=device,
                    multi_gpu=use_multi_gpu,
                    gpu_ids=gpu_ids if use_multi_gpu else None,
                )
                print("  âœ“ DeepCFR with Feature Transform æ±‚è§£å™¨åˆ›å»ºæˆåŠŸï¼ˆå¤æ‚ç‰ˆæœ¬ï¼‰")
                print(f"  âœ“ åŸå§‹ä¿¡æ¯çŠ¶æ€å¤§å°: {deep_cfr_solver._embedding_size} (è‡ªåŠ¨æ£€æµ‹ï¼Œä¿ç•™)")
                print(f"  âœ“ æ‰‹åŠ¨ç‰¹å¾ç»´åº¦: 7 (æ–°å¢)")
                print(f"  âœ“ å¯å­¦ä¹ ç‰¹å¾ç»´åº¦: 64 (æ–°å¢)")
                combined_size = deep_cfr_solver._embedding_size + 7 + 64
                print(f"  âœ“ åˆå¹¶åç»´åº¦: {combined_size} (åŸå§‹{deep_cfr_solver._embedding_size} + æ‰‹åŠ¨7 + å¯å­¦ä¹ 64)")
                print(f"  âœ“ æœ€ç»ˆè¾“å‡ºç»´åº¦: {transformed_size}")
                print(f"  âœ“ ä½¿ç”¨æ··åˆç‰¹å¾è½¬æ¢: {use_hybrid_transform}")
        else:
            # ä½¿ç”¨æ ‡å‡† DeepCFR
            deep_cfr_solver = deep_cfr.DeepCFRSolver(
                game,
                policy_network_layers=policy_layers,
                advantage_network_layers=advantage_layers,
                num_iterations=num_iterations,
                num_traversals=num_traversals,
                learning_rate=learning_rate,
                batch_size_advantage=None,
                batch_size_strategy=None,
                memory_capacity=memory_capacity,
                device=device,
            )
            print("  âœ“ DeepCFR æ±‚è§£å™¨åˆ›å»ºæˆåŠŸï¼ˆæ ‡å‡†ç‰ˆæœ¬ï¼‰")
        
        if use_multi_gpu:
            print(f"  âœ“ å¤š GPU å¹¶è¡Œå·²å¯ç”¨: {gpu_ids}")
        if device.type == "cuda":
            print(f"  âœ“ ä¸»è®¾å¤‡: {device}")
        sys.stdout.flush()
    except Exception as e:
        print(f"  âœ— æ±‚è§£å™¨åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise
    
    # æå‰åˆ›å»ºä¿å­˜ç›®å½•ï¼ˆç”¨äº checkpointï¼‰
    model_dir = create_save_directory(save_prefix, save_dir)
    print(f"\n  æ¨¡å‹ä¿å­˜ç›®å½•: {model_dir}")
    if checkpoint_interval > 0:
        print(f"  Checkpoint ä¿å­˜é—´éš”: æ¯ {checkpoint_interval} æ¬¡è¿­ä»£")
    
    # è®­ç»ƒ
    print(f"\n[3/4] å¼€å§‹è®­ç»ƒ...")
    print(f"  å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  é…ç½®: {num_iterations} æ¬¡è¿­ä»£, æ¯æ¬¡ {num_traversals} æ¬¡éå†")
    print(f"  è®¾å¤‡: {device}")
    start_time = time.time()
    
    # è®­ç»ƒå†å²è®°å½•
    training_history = {
        'config': {
            'num_players': num_players,
            'num_iterations': num_iterations,
            'num_traversals': num_traversals,
            'policy_layers': list(policy_layers),
            'advantage_layers': list(advantage_layers),
            'learning_rate': learning_rate,
            'memory_capacity': memory_capacity,
            'device': str(device),
            'use_feature_transform': use_feature_transform,
            'use_simple_feature': use_simple_feature if use_feature_transform else None,
            'transformed_size': transformed_size if (use_feature_transform and not use_simple_feature) else None,
            'use_hybrid_transform': use_hybrid_transform if (use_feature_transform and not use_simple_feature) else None,
            'betting_abstraction': betting_abstraction,
        },
        'iterations': [],
        'start_time': time.strftime('%Y-%m-%d %H:%M:%S'),
    }
    
    try:
        advantage_losses = {}
        policy_loss = None
        
        # æ‰‹åŠ¨è¿è¡Œè¿­ä»£ä»¥æ˜¾ç¤ºè¿›åº¦
        for iteration in range(num_iterations):
            iter_start = time.time()
            print(f"\n  è¿­ä»£ {iteration + 1}/{num_iterations}...", end="", flush=True)
            
            for player in range(game.num_players()):
                for _ in range(num_traversals):
                    deep_cfr_solver._traverse_game_tree(deep_cfr_solver._root_node, player)
                
                if deep_cfr_solver._reinitialize_advantage_networks:
                    deep_cfr_solver.reinitialize_advantage_network(player)
                
                loss = deep_cfr_solver._learn_advantage_network(player)
                if player not in advantage_losses:
                    advantage_losses[player] = []
                if loss is not None:
                    advantage_losses[player].append(loss)
            
            deep_cfr_solver._iteration += 1
            
            iter_time = time.time() - iter_start
            print(f" å®Œæˆ (è€—æ—¶: {iter_time:.2f}ç§’)", end="", flush=True)
            
            # æ¯ eval_interval æ¬¡è¿­ä»£è¿›è¡Œè¯„ä¼°å’Œæ‰“å°è¯¦ç»†ä¿¡æ¯
            if (iteration + 1) % eval_interval == 0 or iteration == num_iterations - 1:
                if advantage_losses:
                    for player, losses in advantage_losses.items():
                        if losses and losses[-1] is not None:
                            print(f" | ç©å®¶{player}æŸå¤±: {losses[-1]:.6f}", end="")
                if device.type == "cuda":
                    gpu_memory = torch.cuda.memory_allocated(0) / 1e9
                    print(f" | GPUå†…å­˜: {gpu_memory:.2f}GB", end="")
                print()
                
                # è¿›è¡Œè¯„ä¼°ï¼ˆè½»é‡çº§ï¼Œä¸è®¡ç®— NashConvï¼‰
                # æ³¨æ„ï¼šè¯„ä¼°åº”è¯¥æ€»æ˜¯è¿è¡Œï¼ˆå¦‚æœå¯ç”¨ï¼‰ï¼ŒNashConvæ˜¯å¯é€‰çš„
                try:
                    from training_evaluator import quick_evaluate, print_evaluation_summary
                    print(f"\n  è¯„ä¼°è®­ç»ƒæ•ˆæœï¼ˆè¿­ä»£ {iteration + 1}ï¼‰...", end="", flush=True)
                    eval_result = quick_evaluate(
                        game,
                        deep_cfr_solver,
                        include_test_games=eval_with_games,
                        num_test_games=50,
                        max_depth=None,  # è‡ªåŠ¨è®¾ç½®ï¼ˆåŸºäºæ¸¸æˆç‰¹æ€§ï¼‰
                        verbose=False
                    )
                    print(" å®Œæˆ")
                    
                    # æ‰“å°ç®€è¦è¯„ä¼°ä¿¡æ¯
                    metrics = eval_result['metrics']
                    print(f"  ç­–ç•¥ç†µ: {metrics.get('avg_entropy', 0):.4f} | "
                          f"ç­–ç•¥ç¼“å†²åŒº: {metrics.get('strategy_buffer_size', 0):,} | "
                          f"ä¼˜åŠ¿æ ·æœ¬: {metrics.get('total_advantage_samples', 0):,}")
                    
                    if eval_result.get('test_results'):
                        test = eval_result['test_results']
                        print(f"  æµ‹è¯•å¯¹å±€: ç©å®¶0å¹³å‡æ”¶ç›Š={test.get('player0_avg_return', 0):.4f}, "
                              f"èƒœç‡={test.get('player0_win_rate', 0)*100:.1f}%")
                    
                    # è®°å½•è¯„ä¼°ç»“æœåˆ°å†å²
                    if save_history:
                        iteration_record = {
                            'iteration': iteration + 1,
                            'time_elapsed': float(time.time() - start_time),
                            'advantage_losses': {str(p): float(losses[-1]) if losses and losses[-1] is not None else None 
                                                 for p, losses in advantage_losses.items()},
                            'metrics': {
                                'avg_entropy': float(metrics.get('avg_entropy', 0)),
                                'strategy_buffer_size': int(metrics.get('strategy_buffer_size', 0)),
                                'total_advantage_samples': int(metrics.get('total_advantage_samples', 0)),
                            }
                        }
                        if eval_result.get('test_results'):
                            test = eval_result['test_results']
                            iteration_record['test_results'] = {
                                'player0_avg_return': float(test.get('player0_avg_return', 0)),
                                'player0_win_rate': float(test.get('player0_win_rate', 0)),
                            }
                        training_history['iterations'].append(iteration_record)
                except ImportError:
                    # å¦‚æœè¯„ä¼°æ¨¡å—ä¸å­˜åœ¨ï¼Œè·³è¿‡
                    pass
                except Exception as e:
                    # è¯„ä¼°å¤±è´¥ä¸å½±å“è®­ç»ƒ
                    print(f"  âš ï¸ è¯„ä¼°å¤±è´¥: {e}")
            
            # ä¿å­˜ checkpointï¼ˆç‹¬ç«‹äº eval_intervalï¼ŒæŒ‰ checkpoint_interval ä¿å­˜ï¼‰
            if checkpoint_interval > 0 and (iteration + 1) % checkpoint_interval == 0:
                print(f"\n  ğŸ’¾ ä¿å­˜ checkpoint (è¿­ä»£ {iteration + 1})...", end="", flush=True)
                try:
                    save_checkpoint(deep_cfr_solver, game, model_dir, save_prefix, iteration + 1)
                    print(" å®Œæˆ")
                except Exception as e:
                    print(f" å¤±è´¥: {e}")
        
        # è®­ç»ƒç­–ç•¥ç½‘ç»œ
        print("  è®­ç»ƒç­–ç•¥ç½‘ç»œ...", end="", flush=True)
        policy_loss = deep_cfr_solver._learn_strategy_network()
        print(" å®Œæˆ")
        
        total_time = time.time() - start_time
        print(f"\n  âœ“ è®­ç»ƒå®Œæˆï¼")
        print(f"  âœ“ æ€»è€—æ—¶: {total_time:.2f} ç§’ ({total_time/60:.2f} åˆ†é’Ÿ)")
        
        # è®°å½•æœ€ç»ˆç»“æœ
        if save_history:
            training_history['end_time'] = time.strftime('%Y-%m-%d %H:%M:%S')
            training_history['total_time'] = total_time
            training_history['final_losses'] = {}
            if advantage_losses:
                for player, losses in advantage_losses.items():
                    if losses:
                        training_history['final_losses'][f'player_{player}_advantage'] = {
                            'initial': losses[0] if losses[0] is not None else None,
                            'final': losses[-1] if losses[-1] is not None else None,
                        }
            if policy_loss is not None:
                training_history['final_losses']['policy'] = policy_loss
        
        # æ‰“å°æŸå¤±
        if advantage_losses:
            for player, losses in advantage_losses.items():
                if losses and losses[-1] is not None:
                    print(f"  ç©å®¶ {player} ä¼˜åŠ¿æŸå¤±: {losses[0]:.6f} -> {losses[-1]:.6f}")
        
        if policy_loss is not None:
            print(f"  ç­–ç•¥æŸå¤±: {policy_loss:.6f}")
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        # ä¿å­˜ä¸­æ–­æ—¶çš„ checkpoint
        current_iter = deep_cfr_solver._iteration
        print(f"  ğŸ’¾ ä¿å­˜ä¸­æ–­æ—¶çš„ checkpoint (è¿­ä»£ {current_iter})...")
        try:
            checkpoint_dir = save_checkpoint(deep_cfr_solver, game, model_dir, save_prefix, current_iter)
            print(f"  âœ“ Checkpoint å·²ä¿å­˜åˆ°: {checkpoint_dir}")
        except Exception as save_e:
            print(f"  âœ— Checkpoint ä¿å­˜å¤±è´¥: {save_e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nè®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        # å°è¯•ä¿å­˜é”™è¯¯æ—¶çš„ checkpoint
        try:
            current_iter = deep_cfr_solver._iteration
            print(f"  ğŸ’¾ å°è¯•ä¿å­˜é”™è¯¯æ—¶çš„ checkpoint (è¿­ä»£ {current_iter})...")
            checkpoint_dir = save_checkpoint(deep_cfr_solver, game, model_dir, save_prefix, current_iter)
            print(f"  âœ“ Checkpoint å·²ä¿å­˜åˆ°: {checkpoint_dir}")
        except Exception:
            pass
        sys.exit(1)
    
    # ä¿å­˜æ¨¡å‹
    print(f"\n[4/4] ä¿å­˜æœ€ç»ˆæ¨¡å‹...")
    try:
        # ç›®å½•å·²åœ¨è®­ç»ƒå¼€å§‹å‰åˆ›å»º
        print(f"  ä¿å­˜ç›®å½•: {model_dir}")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹ï¼ˆä½¿ç”¨ save_checkpoint å‡½æ•°ï¼‰
        save_checkpoint(deep_cfr_solver, game, model_dir, save_prefix, num_iterations, is_final=True)
        print(f"  âœ“ ç­–ç•¥ç½‘ç»œå·²ä¿å­˜: {os.path.join(model_dir, f'{save_prefix}_policy_network.pt')}")
        for player in range(game.num_players()):
            print(f"  âœ“ ç©å®¶ {player} ä¼˜åŠ¿ç½‘ç»œå·²ä¿å­˜")
        
        # è®¡ç®— NashConvï¼ˆå¯é€‰ï¼Œå¸¦èµ„æºé™åˆ¶ï¼‰
        if not skip_nashconv:
            print(f"\nè®¡ç®— NashConvï¼ˆè¿™å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰...")
            print(f"  æ³¨æ„: ç­–ç•¥æŸ¥è¯¢å·²åœ¨ GPU ä¸Šï¼Œæ¸¸æˆæ ‘éå†åœ¨ C++ å±‚é¢")
            print(f"  âš ï¸ è­¦å‘Š: å¯¹äºå¤§è§„æ¨¡æ¸¸æˆï¼Œå¯èƒ½æ¶ˆè€—å¤§é‡ CPU å’Œå†…å­˜")
            print(f"  å¦‚æœç³»ç»Ÿèµ„æºä¸è¶³ï¼Œå»ºè®®ä½¿ç”¨ --skip_nashconv è·³è¿‡")
            try:
                # ä½¿ç”¨ GPU åŠ é€Ÿçš„ NashConv è®¡ç®—ï¼ˆå¸¦èµ„æºé™åˆ¶ï¼‰
                # é™åˆ¶èµ„æºä½¿ç”¨ï¼Œé¿å…ç³»ç»Ÿå¡æ­»
                from nash_conv_gpu import nash_conv_lightweight
                conv = nash_conv_lightweight(
                    game, 
                    deep_cfr_solver,
                    max_cpu_threads=2,  # é™åˆ¶ CPU çº¿ç¨‹æ•°
                    max_memory_gb=8,    # é™åˆ¶å†…å­˜ä½¿ç”¨ï¼ˆ8GBï¼‰
                    timeout_seconds=600,  # 10 åˆ†é’Ÿè¶…æ—¶
                    verbose=True,
                    device=device
                )
            except ImportError:
                # å›é€€åˆ°æ ‡å‡†æ–¹æ³•ï¼ˆä¸æ¨èï¼Œå¯èƒ½æ¶ˆè€—å¤§é‡èµ„æºï¼‰
                print(f"  âš ï¸ è­¦å‘Š: ä½¿ç”¨æ ‡å‡†æ–¹æ³•ï¼Œå¯èƒ½æ¶ˆè€—å¤§é‡èµ„æº")
                print(f"  å»ºè®®: ä½¿ç”¨ --skip_nashconv è·³è¿‡ï¼Œæˆ–å®‰è£… nash_conv_gpu æ¨¡å—")
                try:
                    average_policy = policy.tabular_policy_from_callable(
                        game, deep_cfr_solver.action_probabilities
                    )
                    pyspiel_policy = policy.python_policy_to_pyspiel_policy(average_policy)
                    conv = pyspiel.nash_conv(game, pyspiel_policy, use_cpp_br=True)
                    print(f"  âœ“ NashConv: {conv:.6f}")
                except MemoryError:
                    print(f"  âœ— å†…å­˜ä¸è¶³ï¼Œæ— æ³•è®¡ç®— NashConv")
                    print(f"  å»ºè®®: ä½¿ç”¨ --skip_nashconv è·³è¿‡")
                except Exception as e:
                    print(f"  âœ— NashConv è®¡ç®—å¤±è´¥: {e}")
                    print(f"  å»ºè®®: ä½¿ç”¨ --skip_nashconv è·³è¿‡")
            except (TimeoutError, MemoryError) as e:
                print(f"\n  âš ï¸ NashConv è®¡ç®—å¤±è´¥: {e}")
                print(f"  å»ºè®®: ä½¿ç”¨ --skip_nashconv è·³è¿‡è®¡ç®—")
            except KeyboardInterrupt:
                print(f"\n  âš ï¸ NashConv è®¡ç®—è¢«ç”¨æˆ·ä¸­æ–­")
            except Exception as e:
                print(f"  âš ï¸ NashConv è®¡ç®—å¤±è´¥: {e}")
                print(f"  å»ºè®®: ä½¿ç”¨ --skip_nashconv è·³è¿‡è®¡ç®—")
        else:
            print(f"\n  â­ï¸ è·³è¿‡ NashConv è®¡ç®—ï¼ˆæ¨èç”¨äºå¤§è§„æ¨¡è®­ç»ƒï¼‰")
        
        # ä¿å­˜è®­ç»ƒå†å²
        if save_history:
            history_path = os.path.join(model_dir, f"{save_prefix}_training_history.json")
            try:
                # ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½æ˜¯ JSON å¯åºåˆ—åŒ–çš„
                serializable_history = json_serialize(training_history)
                with open(history_path, 'w') as f:
                    json.dump(serializable_history, f, indent=2)
                print(f"\n  âœ“ è®­ç»ƒå†å²å·²ä¿å­˜: {history_path}")
            except Exception as e:
                print(f"  âš ï¸ è®­ç»ƒå†å²ä¿å­˜å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        # ä¿å­˜è®­ç»ƒé…ç½®ä¿¡æ¯
        config_path = os.path.join(model_dir, "config.json")
        try:
            config_info = {
                'save_prefix': save_prefix,
                'num_players': num_players,
                'num_iterations': num_iterations,
                'num_traversals': num_traversals,
                'policy_layers': list(policy_layers),
                'advantage_layers': list(advantage_layers),
                'learning_rate': learning_rate,
                'memory_capacity': memory_capacity,
                'device': str(device),
                'use_feature_transform': use_feature_transform,
                'use_simple_feature': use_simple_feature if use_feature_transform else None,
                'transformed_size': transformed_size if (use_feature_transform and not use_simple_feature) else None,
                'use_hybrid_transform': use_hybrid_transform if (use_feature_transform and not use_simple_feature) else None,
                'betting_abstraction': betting_abstraction,
                'multi_gpu': use_multi_gpu,
                'gpu_ids': gpu_ids if use_multi_gpu else None,
                'game_string': game_string,
                'training_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            }
            with open(config_path, 'w') as f:
                json.dump(config_info, f, indent=2)
            print(f"  âœ“ è®­ç»ƒé…ç½®å·²ä¿å­˜: {config_path}")
        except Exception as e:
            print(f"  âš ï¸ é…ç½®ä¿å­˜å¤±è´¥: {e}")
        
    except Exception as e:
        print(f"  âš ï¸ æ¨¡å‹ä¿å­˜æˆ–è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 70)
    print("âœ“ DeepCFR è®­ç»ƒå®Œæˆï¼")
    print("=" * 70)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ä½¿ç”¨ DeepCFR è®­ç»ƒå¾·å·æ‰‘å…‹ç­–ç•¥")
    parser.add_argument("--num_players", type=int, default=2, help="ç©å®¶æ•°é‡")
    parser.add_argument("--num_iterations", type=int, default=10, help="è¿­ä»£æ¬¡æ•°")
    parser.add_argument("--num_traversals", type=int, default=20, help="æ¯æ¬¡è¿­ä»£éå†æ¬¡æ•°")
    parser.add_argument("--policy_layers", type=int, nargs="+", default=[64, 64], help="ç­–ç•¥ç½‘ç»œå±‚å¤§å°")
    parser.add_argument("--advantage_layers", type=int, nargs="+", default=[32, 32], help="ä¼˜åŠ¿ç½‘ç»œå±‚å¤§å°")
    parser.add_argument("--learning_rate", type=float, default=1e-3, help="å­¦ä¹ ç‡")
    parser.add_argument("--memory_capacity", type=int, default=int(1e6), help="å†…å­˜å®¹é‡")
    parser.add_argument("--save_prefix", type=str, default="deepcfr_texas", help="ä¿å­˜æ–‡ä»¶å‰ç¼€")
    parser.add_argument("--save_dir", type=str, default="models", help="æ¨¡å‹ä¿å­˜ç›®å½•ï¼ˆé»˜è®¤: modelsï¼‰")
    parser.add_argument("--use_gpu", action="store_true", default=True, help="ä½¿ç”¨ GPU")
    parser.add_argument("--skip_nashconv", action="store_true", help="è·³è¿‡ NashConv è®¡ç®—")
    parser.add_argument("--eval_interval", type=int, default=10, help="æ¯ N æ¬¡è¿­ä»£è¿›è¡Œä¸€æ¬¡è¯„ä¼°")
    parser.add_argument("--eval_with_games", action="store_true", help="è¯„ä¼°æ—¶åŒ…å«æµ‹è¯•å¯¹å±€")
    parser.add_argument("--save_history", action="store_true", default=True, help="ä¿å­˜è®­ç»ƒå†å²åˆ°JSONæ–‡ä»¶")
    parser.add_argument("--use_feature_transform", action="store_true", default=True, help="ä½¿ç”¨ç‰¹å¾è½¬æ¢å±‚ï¼ˆé»˜è®¤å¯ç”¨ï¼‰")
    parser.add_argument("--no_feature_transform", dest="use_feature_transform", action="store_false", help="ä¸ä½¿ç”¨ç‰¹å¾è½¬æ¢å±‚")
    parser.add_argument("--use_simple_feature", action="store_true", default=True, help="ä½¿ç”¨ç®€å•ç‰ˆæœ¬ï¼ˆç›´æ¥æ‹¼æ¥7ç»´ç‰¹å¾ï¼Œé»˜è®¤å¯ç”¨ï¼Œæ¨èï¼‰")
    parser.add_argument("--no_simple_feature", dest="use_simple_feature", action="store_false", help="ä¸ä½¿ç”¨ç®€å•ç‰ˆæœ¬ï¼ˆä½¿ç”¨å¤æ‚ç‰¹å¾è½¬æ¢å±‚ï¼‰")
    parser.add_argument("--transformed_size", type=int, default=150, help="è½¬æ¢åçš„ç‰¹å¾å¤§å°ï¼ˆä»…ç”¨äºå¤æ‚ç‰ˆæœ¬ï¼Œé»˜è®¤150ï¼‰")
    parser.add_argument("--use_hybrid_transform", action="store_true", default=True, help="ä½¿ç”¨æ··åˆç‰¹å¾è½¬æ¢ï¼ˆä»…ç”¨äºå¤æ‚ç‰ˆæœ¬ï¼Œé»˜è®¤å¯ç”¨ï¼‰")
    parser.add_argument("--no_hybrid_transform", dest="use_hybrid_transform", action="store_false", help="ä¸ä½¿ç”¨æ··åˆç‰¹å¾è½¬æ¢ï¼ˆä»…ç”¨äºå¤æ‚ç‰ˆæœ¬ï¼‰")
    parser.add_argument("--betting_abstraction", type=str, default="fcpa", help="ä¸‹æ³¨æŠ½è±¡: fcpa (é»˜è®¤), fchpa (å«åŠæ± ), fc, fullgame")
    parser.add_argument("--multi_gpu", action="store_true", help="å¯ç”¨å¤š GPU å¹¶è¡Œè®­ç»ƒ")
    parser.add_argument("--gpu_ids", type=int, nargs="+", default=None, help="æŒ‡å®šä½¿ç”¨çš„ GPU ID åˆ—è¡¨ï¼ˆä¾‹å¦‚ --gpu_ids 0 1 2ï¼‰")
    parser.add_argument("--checkpoint_interval", type=int, default=0, help="Checkpoint ä¿å­˜é—´éš”ï¼ˆ0=ä¸ä¿å­˜ä¸­é—´checkpointï¼Œå»ºè®®100-500ï¼‰")
    
    args = parser.parse_args()
    
    train_deep_cfr(
        num_players=args.num_players,
        num_iterations=args.num_iterations,
        num_traversals=args.num_traversals,
        policy_layers=tuple(args.policy_layers),
        advantage_layers=tuple(args.advantage_layers),
        learning_rate=args.learning_rate,
        memory_capacity=args.memory_capacity,
        save_prefix=args.save_prefix,
        save_dir=args.save_dir,
        use_gpu=args.use_gpu,
        skip_nashconv=args.skip_nashconv,
        eval_interval=args.eval_interval,
        eval_with_games=args.eval_with_games,
        save_history=args.save_history,
        use_feature_transform=args.use_feature_transform,
        use_simple_feature=args.use_simple_feature,
        transformed_size=args.transformed_size,
        use_hybrid_transform=args.use_hybrid_transform,
        betting_abstraction=args.betting_abstraction,
        multi_gpu=args.multi_gpu,
        gpu_ids=args.gpu_ids,
        checkpoint_interval=args.checkpoint_interval,
    )
